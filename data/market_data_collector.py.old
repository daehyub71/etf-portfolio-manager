# ==========================================
# data/market_data_collector.py - pykrx ì—°ë™ ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ê¸° (ìˆ˜ì • ë²„ì „)
# ==========================================

import pandas as pd
import numpy as np
import sqlite3
import time
import logging
import os
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import sys
from pathlib import Path

# pykrx import ì‹œë„
try:
    from pykrx import stock
    from pykrx import bond
    PYKRX_AVAILABLE = True
    print("âœ… pykrx ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ê°€ëŠ¥")
except ImportError:
    PYKRX_AVAILABLE = False
    print("âš ï¸ pykrx ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ")
    print("pip install pykrx í›„ ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ ê°€ëŠ¥")

# ì˜ì—…ì¼ ê³„ì‚°ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import pandas_market_calendars as mcal
    MARKET_CALENDAR_AVAILABLE = True
except ImportError:
    MARKET_CALENDAR_AVAILABLE = False
    print("âš ï¸ pandas_market_calendars ì—†ìŒ - ê¸°ë³¸ ì˜ì—…ì¼ ê³„ì‚° ì‚¬ìš©")

# ì›¹ ìŠ¤í¬ë˜í•‘ì„ ìœ„í•œ ì¶”ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import requests
    from bs4 import BeautifulSoup
    WEB_SCRAPING_AVAILABLE = True
    print("âœ… ì›¹ ìŠ¤í¬ë˜í•‘ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ê°€ëŠ¥")
except ImportError:
    WEB_SCRAPING_AVAILABLE = False
    print("âš ï¸ ì›¹ ìŠ¤í¬ë˜í•‘ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ")
    print("pip install requests beautifulsoup4 í›„ ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ ê°€ëŠ¥")

logger = logging.getLogger(__name__)

class MarketDataCollector:
    """pykrx ê¸°ë°˜ ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ê¸° (ì˜¤ë¥˜ ìˆ˜ì • ë²„ì „)"""
    
    def __init__(self, db_path: str = "etf_universe.db", safe_mode: bool = True):
        self.db_path = db_path
        self.safe_mode = safe_mode  # ì•ˆì „ ëª¨ë“œ í”Œë˜ê·¸
        self.setup_logging()
        
        # ì•ˆì „ ëª¨ë“œì— ë”°ë¥¸ API í˜¸ì¶œ ì œí•œ ì„¤ì •
        if safe_mode:
            self.api_delay = 1.0  # ì•ˆì „ ëª¨ë“œ: 1ì´ˆ ì§€ì—°
            logger.info("ğŸ›¡ï¸ ì•ˆì „ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤")
        else:
            self.api_delay = 0.2  # ì¼ë°˜ ëª¨ë“œ: 200ms ì§€ì—°
            
        self.last_api_call = 0
        
        # ìºì‹œ ì„¤ì •
        self.cache = {}
        self.cache_ttl = 3600  # 1ì‹œê°„ ìºì‹œ
        
        # ì›¹ ìŠ¤í¬ë˜í•‘ ì„¸ì…˜ ì„¤ì •
        if WEB_SCRAPING_AVAILABLE:
            self.session = requests.Session()
            self.session.headers.update({
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            })
        else:
            self.session = None
        
        logger.info(f"MarketDataCollector ì´ˆê¸°í™” (DB: {db_path}, ì•ˆì „ëª¨ë“œ: {safe_mode}, ì§€ì—°: {self.api_delay}s)")
    
    def setup_logging(self):
        """ë¡œê¹… ì„¤ì • (ì™„ì „ ì•ˆì „ ë²„ì „)"""
        if not logger.handlers:
            handler = logging.StreamHandler()
            # ë§¤ìš° ì•ˆì „í•œ í¬ë§·í„° ì‚¬ìš©
            formatter = logging.Formatter(
                '[%(asctime)s] %(name)s - %(levelname)s - %(message)s',
                datefmt='%H:%M:%S'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            logger.setLevel(logging.INFO)
            
            # ì¶”ê°€ì ì¸ ë¡œê¹… ì•ˆì „ì¥ì¹˜
            logger.propagate = False
            
            # pykrx ë¡œê¹… ë ˆë²¨ ì¡°ì • (ë¬¸ì œê°€ ë˜ëŠ” ë¡œê¹… ì–µì œ)
            try:
                pykrx_logger = logging.getLogger('pykrx')
                pykrx_logger.setLevel(logging.ERROR)  # ERROR ì´ìƒë§Œ ë¡œê¹…
                
                # root ë¡œê±°ì˜ ë ˆë²¨ë„ ì¡°ì •
                root_logger = logging.getLogger()
                if root_logger.level < logging.WARNING:
                    root_logger.setLevel(logging.WARNING)
                    
            except:
                pass  # ë¡œê¹… ì„¤ì • ì‹¤íŒ¨í•´ë„ ë¬´ì‹œ
    
    def _rate_limit(self):
        """API í˜¸ì¶œ ì œí•œ"""
        now = time.time()
        elapsed = now - self.last_api_call
        if elapsed < self.api_delay:
            time.sleep(self.api_delay - elapsed)
        self.last_api_call = time.time()
    
    def _get_cache_key(self, *args) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        return "_".join(str(arg) for arg in args)
    
    def _is_cache_valid(self, key: str) -> bool:
        """ìºì‹œ ìœ íš¨ì„± í™•ì¸"""
        if key not in self.cache:
            return False
        
        cached_time, _ = self.cache[key]
        return (time.time() - cached_time) < self.cache_ttl
    
    def _get_cache(self, key: str):
        """ìºì‹œì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        if self._is_cache_valid(key):
            _, data = self.cache[key]
            return data
        return None
    
    def _set_cache(self, key: str, data):
        """ìºì‹œì— ë°ì´í„° ì €ì¥"""
        self.cache[key] = (time.time(), data)
    
    def get_last_business_day(self, date: datetime = None) -> str:
        """ìµœì¢… ì˜ì—…ì¼ ê³„ì‚°"""
        if date is None:
            date = datetime.now()
        
        # í•œêµ­ ì‹œì¥ ê¸°ì¤€ ì˜ì—…ì¼ ê³„ì‚°
        if MARKET_CALENDAR_AVAILABLE:
            try:
                # í•œêµ­ ì‹œì¥ ìº˜ë¦°ë” ì‚¬ìš©
                krx = mcal.get_calendar('XKRX')  # í•œêµ­ê±°ë˜ì†Œ
                
                # ìµœê·¼ 5ì¼ê°„ì˜ ì˜ì—…ì¼ ì¡°íšŒ
                end_date = date
                start_date = date - timedelta(days=10)
                
                business_days = krx.valid_days(
                    start_date=start_date,
                    end_date=end_date
                )
                
                if len(business_days) > 0:
                    last_business_day = business_days[-1].strftime('%Y%m%d')
                    logger.info(f"í•œêµ­ê±°ë˜ì†Œ ì˜ì—…ì¼ ê¸°ì¤€ ìµœì¢…ì¼: {last_business_day}")
                    return last_business_day
                    
            except Exception as e:
                logger.warning(f"ì‹œì¥ ìº˜ë¦°ë” ì‚¬ìš© ì‹¤íŒ¨: {e}")
        
        # ê¸°ë³¸ ì˜ì—…ì¼ ê³„ì‚° (ì£¼ë§ ì œì™¸)
        current_date = date
        while current_date.weekday() >= 5:  # í† ìš”ì¼(5), ì¼ìš”ì¼(6) ì œì™¸
            current_date -= timedelta(days=1)
        
        # í•œêµ­ì˜ ì£¼ìš” ê³µíœ´ì¼ ì²´í¬ (ê°„ë‹¨ ë²„ì „)
        holidays_2024 = [
            '20241225',  # í¬ë¦¬ìŠ¤ë§ˆìŠ¤
            '20241231',  # ì—°ë§
        ]
        
        holidays_2025 = [
            '20250101',  # ì‹ ì •
            '20250127', '20250128', '20250129',  # ì„¤ë‚  ì—°íœ´
            '20250301',  # ì‚¼ì¼ì ˆ
            '20250505',  # ì–´ë¦°ì´ë‚ 
            '20250506',  # ì–´ë¦°ì´ë‚  ëŒ€ì²´íœ´ì¼
            '20250815',  # ê´‘ë³µì ˆ
            '20251003',  # ê°œì²œì ˆ
            '20251006', '20251007', '20251008',  # ì¶”ì„ ì—°íœ´
            '20251009',  # í•œê¸€ë‚ 
            '20251225',  # í¬ë¦¬ìŠ¤ë§ˆìŠ¤
        ]
        
        all_holidays = holidays_2024 + holidays_2025
        
        # ê³µíœ´ì¼ ì²´í¬
        while current_date.strftime('%Y%m%d') in all_holidays:
            current_date -= timedelta(days=1)
            # ì£¼ë§ì´ë©´ ë‹¤ì‹œ ì¡°ì •
            while current_date.weekday() >= 5:
                current_date -= timedelta(days=1)
        
        last_business_day = current_date.strftime('%Y%m%d')
        logger.info(f"ê³„ì‚°ëœ ìµœì¢… ì˜ì—…ì¼: {last_business_day}")
        return last_business_day
    
    def get_all_etf_list(self) -> List[Dict]:
        """ì „ì²´ ETF ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ"""
        cache_key = "all_etf_list"
        cached_data = self._get_cache(cache_key)
        if cached_data:
            logger.info("ìºì‹œì—ì„œ ETF ë¦¬ìŠ¤íŠ¸ ë°˜í™˜")
            return cached_data
        
        if not PYKRX_AVAILABLE:
            logger.warning("pykrx ì—†ìŒ - ê¸°ë³¸ ETF ë¦¬ìŠ¤íŠ¸ ë°˜í™˜")
            return self._get_default_etf_list()
        
        try:
            logger.info("pykrxë¡œ ì „ì²´ ETF ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ ì‹œì‘")
            self._rate_limit()
            
            # ETF ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            etf_tickers = stock.get_etf_ticker_list()
            logger.info(f"ETF ì¢…ëª© {len(etf_tickers)}ê°œ ì¡°íšŒ ì™„ë£Œ")
            
            # ì•Œë ¤ì§„ ë¬¸ì œ ì¢…ëª©ë“¤ì€ ë” í¬ê´„ì ìœ¼ë¡œ ì œì™¸
            problematic_tickers = [
                # ì§ì ‘ í™•ì¸ëœ ë¬¸ì œ ì¢…ëª©ë“¤
                '427120',  # KBSTAR ì¤‘ê¸° - í€ë”ë©˜í„¸ ì˜¤ë¥˜
                '495710',  # TIMEFOLIO Koreaí”ŒëŸ¬ìŠ¤ë°°ë‹¹ì•¡í‹°ë¸Œ - ISIN ì˜¤ë¥˜
                
                # ê¸°íƒ€ ë¬¸ì œ ê°€ëŠ¥ì„±ì´ ë†’ì€ ì¢…ëª©ë“¤
                '407300',  # KODEX ë¯¸ë˜ì—ì…‹ - ë³µì¡í•œ êµ¬ì¡°
                '449770',  # ë ˆë²„ë¦¬ì§€ ETF - ë³µì¡í•œ êµ¬ì¡°
                '458730',  # ì¸ë²„ìŠ¤ ETF - ë³µì¡í•œ êµ¬ì¡°
                '117460',  # ì¸ë²„ìŠ¤ ETF - ë³µì¡í•œ êµ¬ì¡°
                '251350',  # ë ˆë²„ë¦¬ì§€ ETF - ë³µì¡í•œ êµ¬ì¡°
            ]
            
            # íŒ¨í„´ ê¸°ë°˜ ë¬¸ì œ ì¢…ëª© ì¶”ê°€ í•„í„°ë§ (ë” ì—„ê²©í•˜ê²Œ)
            additional_problematic = []
            for ticker in etf_tickers:
                # ë‹¤ìŒ íŒ¨í„´ì˜ ETFëŠ” ë¬¸ì œê°€ ë  ê°€ëŠ¥ì„±ì´ ë†’ìŒ
                if (ticker.startswith('40') or   # 407xxx, 408xxx ë“± ë³µì¡í•œ êµ¬ì¡°
                    ticker.startswith('41') or   # ë³µì¡í•œ íŒŒìƒìƒí’ˆ ETF
                    ticker.startswith('42') or   # 427xxx ì‹œë¦¬ì¦ˆ (ë¬¸ì œ í™•ì¸ë¨)
                    ticker.startswith('44') or   # ë ˆë²„ë¦¬ì§€/ì¸ë²„ìŠ¤ ETF ë§ìŒ
                    ticker.startswith('45') or   # ë³µì¡í•œ êµ¬ì¡° ETF
                    ticker.startswith('49') or   # 495xxx ì‹œë¦¬ì¦ˆ (ë¬¸ì œ í™•ì¸ë¨)
                    ticker.startswith('11') or   # 117xxx ì¸ë²„ìŠ¤ ETF
                    ticker.startswith('25') or   # 251xxx ë ˆë²„ë¦¬ì§€ ETF
                    len(ticker) != 6 or          # ë¹„ì •ìƒì ì¸ ê¸¸ì´
                    not ticker.isdigit()):       # ìˆ«ìê°€ ì•„ë‹Œ ë¬¸ì í¬í•¨
                    additional_problematic.append(ticker)
            
            all_problematic = problematic_tickers + additional_problematic
            filtered_tickers = [ticker for ticker in etf_tickers if ticker not in all_problematic]
            
            if len(filtered_tickers) != len(etf_tickers):
                excluded_count = len(etf_tickers) - len(filtered_tickers)
                logger.warning(f"ë¬¸ì œ ê°€ëŠ¥ì„± ì¢…ëª© {excluded_count}ê°œ ì œì™¸ë¨")
                logger.debug(f"ì œì™¸ëœ ì¢…ëª©ë“¤: {all_problematic[:10]}...")  # ì²˜ìŒ 10ê°œë§Œ ë¡œê¹…
            
            # ì•ˆì „í•œ ETFë§Œ ì„ ë³„ (í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ë°©ì‹ìœ¼ë¡œ ë” ì—„ê²©í•˜ê²Œ)
            safe_tickers = []
            for ticker in etf_tickers:
                # ë¬¸ì œ ì¢…ëª© ë¨¼ì € ì œì™¸
                if ticker in all_problematic:
                    continue
                    
                # ì•ˆì „í•œ ETFë§Œ ì„ íƒ
                if self._is_safe_etf(ticker):
                    safe_tickers.append(ticker)
            
            logger.info(f"ì•ˆì „í•œ ETF {len(safe_tickers)}ê°œ ì„ ë³„ë¨ (ì „ì²´ {len(etf_tickers)}ê°œ ì¤‘, ì œì™¸ {len(all_problematic)}ê°œ)")
            
            # ì„ ë³„ëœ ì•ˆì „í•œ ETFë“¤ ë¡œê¹…
            if safe_tickers:
                logger.debug(f"ì„ ë³„ëœ ETF: {safe_tickers[:10]}...")  # ì²˜ìŒ 10ê°œë§Œ
            
            etf_list = []
            last_business_day = self.get_last_business_day()
            
            # ê° ETFì˜ ê¸°ë³¸ ì •ë³´ ì¡°íšŒ (ë” ì‘ì€ ë°°ì¹˜ë¡œ ì•ˆì „í•˜ê²Œ)
            batch_size = 2  # ë§¤ìš° ì‘ì€ ë°°ì¹˜ë¡œ ì•ˆì „ì„± í™•ë³´
            success_count = 0
            error_count = 0
            
            # ìµœëŒ€ ì²˜ë¦¬í•  ETF ìˆ˜ ì œí•œ (ë„ˆë¬´ ë§ìœ¼ë©´ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¼)
            max_etfs = min(50, len(safe_tickers))
            processing_tickers = safe_tickers[:max_etfs]
            
            logger.info(f"ì²˜ë¦¬í•  ETF: {len(processing_tickers)}ê°œ (ìµœëŒ€ {max_etfs}ê°œë¡œ ì œí•œ)")
            
            for i in range(0, len(processing_tickers), batch_size):
                batch_tickers = processing_tickers[i:i+batch_size]
                logger.info(f"ETF ì •ë³´ ì¡°íšŒ: {i+1}-{min(i+batch_size, len(processing_tickers))}/{len(processing_tickers)}")
                
                for ticker in batch_tickers:
                    try:
                        self._rate_limit()
                        
                        # ETF ê¸°ë³¸ ì •ë³´ ì¡°íšŒ (ë” ì•ˆì „í•œ ë°©ì‹)
                        etf_info = self._get_etf_basic_info_safe(ticker, last_business_day)
                        if etf_info:
                            etf_list.append(etf_info)
                            success_count += 1
                            logger.debug(f"ETF {ticker} ì¡°íšŒ ì„±ê³µ")
                        else:
                            error_count += 1
                            logger.debug(f"ETF {ticker} ì •ë³´ ì—†ìŒ")
                        
                    except Exception as e:
                        error_count += 1
                        logger.warning(f"ETF {ticker} ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)[:50]}...")
                        continue
                
                # ë°°ì¹˜ë§ˆë‹¤ ë” ê¸´ ì§€ì—°
                if i + batch_size < len(processing_tickers):
                    time.sleep(2.0)  # 2ì´ˆ ì§€ì—°ìœ¼ë¡œ ë” ì•ˆì „í•˜ê²Œ
                
                # ì¤‘ê°„ ê²°ê³¼ í™•ì¸
                if len(etf_list) >= 20:
                    logger.info(f"ì¤‘ê°„ ê²°ê³¼: {len(etf_list)}ê°œ ETF ìˆ˜ì§‘ë¨ (ì„±ê³µë¥ : {success_count}/{success_count+error_count})")
                    # ì¶©ë¶„í•œ ETFê°€ ìˆ˜ì§‘ë˜ë©´ ì¡°ê¸° ì¢…ë£Œ
                    break
            
            logger.info(f"ETF ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ: {len(etf_list)}ê°œ (ì„±ê³µ: {success_count}, ì‹¤íŒ¨: {error_count})")
            
            # ê²°ê³¼ê°€ ë¶€ì¡±í•˜ë©´ ê¸°ë³¸ ë¦¬ìŠ¤íŠ¸ë¡œ ë³´ì™„
            if len(etf_list) < 10:
                logger.warning("ìˆ˜ì§‘ëœ ETFê°€ ë¶€ì¡±í•¨ - ê¸°ë³¸ ë¦¬ìŠ¤íŠ¸ë¡œ ë³´ì™„")
                default_etfs = self._get_default_etf_list()
                # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ ì¶”ê°€
                existing_codes = {etf['code'] for etf in etf_list}
                for default_etf in default_etfs:
                    if default_etf['code'] not in existing_codes:
                        etf_list.append(default_etf)
            
            # ìºì‹œì— ì €ì¥
            self._set_cache(cache_key, etf_list)
            
            return etf_list
            
        except Exception as e:
            logger.error(f"ETF ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return self._get_default_etf_list()
    
    def _get_etf_basic_info_safe(self, ticker: str, date: str) -> Optional[Dict]:
        """ì™„ì „íˆ ì•ˆì „í•œ ETF ê¸°ë³¸ ì •ë³´ ì¡°íšŒ (ìƒì„¸ì •ë³´ í¬í•¨)"""
        try:
            # ETF ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘
            etf_info = {
                'code': ticker,
                'name': self._get_etf_name(ticker),
                'category': self._classify_etf_category(ticker),
                'market_price': 0,
                'aum': 0,
                'volume': 0,
                'expense_ratio': 0.0,
                'dividend_yield': 0.0,
                'nav': 0.0,
                'tracking_error': 0.0,
                'last_updated': datetime.now().isoformat()
            }
            
            # ê°€ê²© ì •ë³´ë§Œ ì¡°íšŒ (í€ë”ë©˜í„¸ì€ ì™„ì „íˆ ì œì™¸)
            try:
                # pykrx í˜¸ì¶œ ìµœì†Œí™”
                price_data = stock.get_market_ohlcv_by_date(date, date, ticker)
                if not price_data.empty:
                    last_row = price_data.iloc[-1]
                    
                    # ì•ˆì „í•œ ì»¬ëŸ¼ ì ‘ê·¼
                    if 'ì¢…ê°€' in price_data.columns:
                        etf_info['market_price'] = float(last_row['ì¢…ê°€'])
                    elif len(price_data.columns) >= 4:
                        etf_info['market_price'] = float(last_row.iloc[3])  # ì¢…ê°€ ìœ„ì¹˜
                    
                    if 'ê±°ë˜ëŸ‰' in price_data.columns:
                        etf_info['volume'] = int(last_row['ê±°ë˜ëŸ‰'])
                    elif len(price_data.columns) >= 5:
                        etf_info['volume'] = int(last_row.iloc[4])  # ê±°ë˜ëŸ‰ ìœ„ì¹˜
                        
                    logger.debug(f"ETF {ticker} ê°€ê²© ì¡°íšŒ ì„±ê³µ: {etf_info['market_price']:,}ì›")
                        
            except Exception as e:
                logger.debug(f"ETF {ticker} ê°€ê²© ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
                # ê°€ê²© ì¡°íšŒ ì‹¤íŒ¨ì‹œ ì¶”ì •ê°’ ì‚¬ìš©
                etf_info['market_price'] = self._estimate_etf_price(ticker)
                etf_info['volume'] = 100000  # ê¸°ë³¸ ê±°ë˜ëŸ‰
            
            # ìƒì„¸ ì •ë³´ ì¡°íšŒ (ë„¤ì´ë²„ ê¸ˆìœµ API + ìŠ¤í¬ë˜í•‘)
            try:
                detailed_info = self.get_comprehensive_etf_details(ticker)
                etf_info.update(detailed_info)
                logger.debug(f"ETF {ticker} ìƒì„¸ì •ë³´ ì¡°íšŒ ì„±ê³µ")
            except Exception as e:
                logger.debug(f"ETF {ticker} ìƒì„¸ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
                # ì‹¤íŒ¨ì‹œ ì •ì  ë°ì´í„° ì‚¬ìš©
                static_details = self._get_static_etf_data(ticker)
                etf_info.update(static_details)
            
            # AUMì€ í•­ìƒ ì¶”ì •ê°’ ì‚¬ìš© (í€ë”ë©˜í„¸ ì¡°íšŒ ì•ˆí•¨)
            etf_info['aum'] = self._estimate_etf_aum(ticker)
            
            # ìµœì¢… ê²€ì¦
            if etf_info['market_price'] > 0:
                return etf_info
            else:
                logger.debug(f"ETF {ticker}: ê°€ê²© ì •ë³´ ë¶€ì¡±, ê¸°ë³¸ê°’ ì‚¬ìš©")
                etf_info['market_price'] = self._estimate_etf_price(ticker)
                return etf_info
                
        except Exception as e:
            logger.debug(f"ETF {ticker} ì•ˆì „ ì¡°íšŒ ì‹¤íŒ¨: {str(e)[:30]}...")
            # ì™„ì „ ì‹¤íŒ¨ì‹œì—ë„ ìµœì†Œ ì •ë³´ ë°˜í™˜
            static_details = self._get_static_etf_data(ticker)
            return {
                'code': ticker,
                'name': self._get_etf_name(ticker),
                'category': self._classify_etf_category(ticker),
                'market_price': self._estimate_etf_price(ticker),
                'aum': self._estimate_etf_aum(ticker),
                'volume': 100000,
                'expense_ratio': static_details.get('expense_ratio', 0.25),
                'dividend_yield': static_details.get('dividend_yield', 1.5),
                'nav': 0.0,
                'tracking_error': static_details.get('tracking_error', 0.15),
                'last_updated': datetime.now().isoformat()
            }
    
    def _estimate_etf_aum(self, ticker: str) -> float:
        """ETF AUM ì¶”ì • (ì–µì› ë‹¨ìœ„)"""
        aum_estimates = {
            '069500': 20000,    # KODEX 200 - ëŒ€í˜•
            '360750': 25000,    # TIGER ë¯¸êµ­S&P500 - ëŒ€í˜•
            '102110': 15000,    # TIGER 200 - ëŒ€í˜•
            '114260': 3000,     # KODEX êµ­ê³ ì±„10ë…„ - ì¤‘í˜•
            '133690': 8000,     # KODEX ë‚˜ìŠ¤ë‹¥100 - ì¤‘í˜•
            '427120': 1200,     # KBSTAR ì¤‘ê¸° - ì†Œí˜•
            '495710': 800,      # TIMEFOLIO Koreaí”ŒëŸ¬ìŠ¤ë°°ë‹¹ì•¡í‹°ë¸Œ - ì†Œí˜•
        }
        
        # í‹°ì»¤ íŒ¨í„´ ê¸°ë°˜ ì¶”ì •
        if ticker.startswith('069') or ticker.startswith('102') or ticker.startswith('360'):
            return aum_estimates.get(ticker, 10000)  # ëŒ€í˜• ETF
        elif ticker.startswith('114') or ticker.startswith('133'):
            return aum_estimates.get(ticker, 3000)   # ì¤‘í˜• ETF
        else:
            return aum_estimates.get(ticker, 1000)   # ì†Œí˜• ETF
    
    def _get_etf_basic_info(self, ticker: str, date: str) -> Optional[Dict]:
        """ê°œë³„ ETF ê¸°ë³¸ ì •ë³´ ì¡°íšŒ (ì™„ì „ ì•ˆì „ ë²„ì „)"""
        try:
            # ë¬¸ìì—´ ë‚ ì§œë¥¼ datetimeìœ¼ë¡œ ë³€í™˜
            if isinstance(date, str):
                try:
                    date_obj = datetime.strptime(date, '%Y%m%d')
                except:
                    date_obj = datetime.now()
            else:
                date_obj = date
            
            # ì˜ì—…ì¼ ì²´í¬
            if date_obj.weekday() >= 5:  # ì£¼ë§
                logger.debug(f"ì£¼ë§ì…ë‹ˆë‹¤. ë§ˆì§€ë§‰ ì˜ì—…ì¼ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                date = self.get_last_business_day(date_obj)
            
            # ETF ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘
            etf_info = {
                'code': ticker,
                'name': self._get_etf_name(ticker),
                'category': self._classify_etf_category(ticker),
                'market_price': 0,
                'aum': 0,
                'volume': 0,
                'last_updated': datetime.now().isoformat()
            }
            
            # ìµœì‹  ê°€ê²© ì •ë³´ ì¡°íšŒ (ì•ˆì „í•œ ë°©ì‹)
            try:
                price_data = stock.get_market_ohlcv_by_date(date, date, ticker)
                if not price_data.empty:
                    # ë§ˆì§€ë§‰ í–‰ì˜ ë°ì´í„° ì‚¬ìš©
                    last_row = price_data.iloc[-1]
                    
                    # ì»¬ëŸ¼ëª…ì´ í•œê¸€ì¸ì§€ í™•ì¸í•˜ê³  ì•ˆì „í•˜ê²Œ ì¶”ì¶œ
                    if 'ì¢…ê°€' in price_data.columns:
                        etf_info['market_price'] = float(last_row['ì¢…ê°€'])
                    elif 'close' in price_data.columns:
                        etf_info['market_price'] = float(last_row['close'])
                    else:
                        # ë§ˆì§€ë§‰ì—ì„œ ë‘ ë²ˆì§¸ ì»¬ëŸ¼ì„ ì¢…ê°€ë¡œ ê°€ì • (ì¼ë°˜ì ì¸ OHLCV ìˆœì„œ)
                        etf_info['market_price'] = float(last_row.iloc[-2])
                    
                    if 'ê±°ë˜ëŸ‰' in price_data.columns:
                        etf_info['volume'] = int(last_row['ê±°ë˜ëŸ‰'])
                    elif 'volume' in price_data.columns:
                        etf_info['volume'] = int(last_row['volume'])
                    else:
                        # ë§ˆì§€ë§‰ ì»¬ëŸ¼ì„ ê±°ë˜ëŸ‰ìœ¼ë¡œ ê°€ì •
                        etf_info['volume'] = int(last_row.iloc[-1])
                        
            except Exception as e:
                logger.debug(f"ETF {ticker} ê°€ê²© ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
                # ê¸°ë³¸ê°’ ìœ ì§€
            
            # âš ï¸ í€ë”ë©˜í„¸ ì¡°íšŒë¥¼ ì™„ì „íˆ ê±´ë„ˆë›°ê¸°
            # pykrxì˜ get_market_fundamental_by_dateê°€ ë¶ˆì•ˆì •í•˜ë¯€ë¡œ ë¹„í™œì„±í™”
            try:
                # ETFëŠ” í€ë”ë©˜í„¸ ì •ë³´ê°€ ì—†ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ê¸°ë³¸ê°’ ì‚¬ìš©
                # ì‹œê°€ì´ì•¡ ëŒ€ì‹  ê±°ë˜ëŒ€ê¸ˆìœ¼ë¡œ AUM ì¶”ì •
                if etf_info['market_price'] > 0 and etf_info['volume'] > 0:
                    # ê±°ë˜ëŒ€ê¸ˆ ê¸°ë°˜ ì¶”ì • (ë§¤ìš° ëŒ€ëµì )
                    estimated_market_value = etf_info['market_price'] * etf_info['volume']
                    etf_info['aum'] = estimated_market_value / 100000000  # ì–µì› ë‹¨ìœ„
                else:
                    # í‹°ì»¤ ê¸°ë°˜ ê¸°ë³¸ AUM ì¶”ì •
                    etf_info['aum'] = self._estimate_etf_aum(ticker)
                    
                logger.debug(f"ETF {ticker} í€ë”ë©˜í„¸ ì¡°íšŒ ê±´ë„ˆë›°ê¸° (ì•ˆì „ ëª¨ë“œ)")
                
            except Exception as e:
                logger.debug(f"ETF {ticker} AUM ì¶”ì • ì‹¤íŒ¨: {e}")
                etf_info['aum'] = self._estimate_etf_aum(ticker)
            
            # ìµœì†Œí•œì˜ ê²€ì¦ - ê°€ê²© ì •ë³´ê°€ ìˆìœ¼ë©´ ì„±ê³µ
            if etf_info['market_price'] > 0:
                logger.debug(f"ETF {ticker} ì •ë³´ ì¡°íšŒ ì„±ê³µ: {etf_info['market_price']:,}ì›")
                return etf_info
            else:
                # ê°€ê²© ì •ë³´ë„ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ETF ì •ë³´ë§Œ ë°˜í™˜
                logger.debug(f"ETF {ticker}: ê°€ê²© ì •ë³´ ì—†ìŒ, ê¸°ë³¸ ì •ë³´ë§Œ ë°˜í™˜")
                etf_info['market_price'] = self._estimate_etf_price(ticker)
                etf_info['aum'] = self._estimate_etf_aum(ticker)
                return etf_info
                
        except Exception as e:
            logger.warning(f"ETF {ticker} ê¸°ë³¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)[:50]}...")
            # ì™„ì „ ì‹¤íŒ¨ì‹œì—ë„ ê¸°ë³¸ ì •ë³´ë¼ë„ ë°˜í™˜
            return {
                'code': ticker,
                'name': self._get_etf_name(ticker),
                'category': self._classify_etf_category(ticker),
                'market_price': self._estimate_etf_price(ticker),
                'aum': self._estimate_etf_aum(ticker),
                'volume': 100000,  # ê¸°ë³¸ ê±°ë˜ëŸ‰
                'last_updated': datetime.now().isoformat()
            }
    
    def _estimate_etf_price(self, ticker: str) -> float:
        """ETF ê¸°ë³¸ ê°€ê²© ì¶”ì •"""
        price_estimates = {
            '069500': 28400,    # KODEX 200
            '360750': 15800,    # TIGER ë¯¸êµ­S&P500
            '114260': 108500,   # KODEX êµ­ê³ ì±„10ë…„
            '133690': 22100,    # KODEX ë‚˜ìŠ¤ë‹¥100
            '102110': 28350,    # TIGER 200
            '427120': 98500,    # KBSTAR ì¤‘ê¸°
            '495710': 9850,     # TIMEFOLIO Koreaí”ŒëŸ¬ìŠ¤ë°°ë‹¹ì•¡í‹°ë¸Œ
        }
        
        # í‹°ì»¤ íŒ¨í„´ ê¸°ë°˜ ì¶”ì •
        if ticker.startswith('069') or ticker.startswith('102'):  # ëŒ€í˜•ì£¼ ETF
            return price_estimates.get(ticker, 25000)
        elif ticker.startswith('114') or ticker.startswith('427'):  # ì±„ê¶Œ ETF
            return price_estimates.get(ticker, 100000)
        elif ticker.startswith('360') or ticker.startswith('133'):  # í•´ì™¸ ETF
            return price_estimates.get(ticker, 18000)
        else:
            return price_estimates.get(ticker, 12000)  # ê¸°íƒ€ ETF
    
    def get_naver_etf_info(self, ticker: str) -> Dict:
        """ë„¤ì´ë²„ ê¸ˆìœµ APIë¡œ ETF ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
        if not WEB_SCRAPING_AVAILABLE:
            return {}
        
        try:
            # ë„¤ì´ë²„ ê¸ˆìœµ ì‹¤ì‹œê°„ API ì—”ë“œí¬ì¸íŠ¸
            api_url = f"https://polling.finance.naver.com/api/realtime/domestic/etf/{ticker}"
            
            response = self.session.get(api_url, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                
                # API ì‘ë‹µì—ì„œ í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ
                etf_info = {}
                
                if 'etfTabContent' in data:
                    tab_content = data['etfTabContent']
                    
                    # ìš´ì˜ë³´ìˆ˜ (ê´€ë¦¬ë¹„ìš©)
                    if 'managementExpenseRatio' in tab_content:
                        etf_info['expense_ratio'] = float(tab_content['managementExpenseRatio'])
                    
                    # ë°°ë‹¹ìˆ˜ìµë¥ 
                    if 'dividendYield' in tab_content:
                        etf_info['dividend_yield'] = float(tab_content['dividendYield'])
                    
                    # NAV (ìˆœìì‚°ê°€ì¹˜)
                    if 'nav' in tab_content:
                        etf_info['nav'] = float(tab_content['nav'])
                    
                    # ì¶”ì ì˜¤ì°¨
                    if 'trackingError' in tab_content:
                        etf_info['tracking_error'] = float(tab_content['trackingError'])
                
                logger.debug(f"ë„¤ì´ë²„ API ETF {ticker} ì •ë³´ ì¡°íšŒ ì„±ê³µ")
                return etf_info
                
            else:
                logger.debug(f"ë„¤ì´ë²„ API ETF {ticker} ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
                return {}
                
        except Exception as e:
            logger.debug(f"ë„¤ì´ë²„ API ETF {ticker} ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    def scrape_naver_etf_info(self, ticker: str) -> Dict:
        """ë„¤ì´ë²„ ê¸ˆìœµ ì›¹ ìŠ¤í¬ë˜í•‘ìœ¼ë¡œ ETF ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
        if not WEB_SCRAPING_AVAILABLE:
            return {}
        
        try:
            # ë„¤ì´ë²„ ê¸ˆìœµ ETF ìƒì„¸ í˜ì´ì§€
            url = f"https://finance.naver.com/item/main.naver?code={ticker}"
            
            response = self.session.get(url, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            etf_info = {}
            
            # ETF ì •ë³´ í…Œì´ë¸”ì—ì„œ ë°ì´í„° ì¶”ì¶œ
            info_tables = soup.select('.tb_type1, .tb_type2')
            
            for table in info_tables:
                rows = table.select('tr')
                for row in rows:
                    cells = row.select('td, th')
                    if len(cells) >= 2:
                        key = cells[0].get_text(strip=True)
                        value = cells[1].get_text(strip=True)
                        
                        # ìš´ì˜ë³´ìˆ˜ / ê´€ë¦¬ë¹„ìš©
                        if 'ìš´ì˜ë³´ìˆ˜' in key or 'ê´€ë¦¬ë¹„ìš©' in key:
                            try:
                                # "0.15%" -> 0.15 ë³€í™˜
                                expense_ratio = float(value.replace('%', '').replace(',', ''))
                                etf_info['expense_ratio'] = expense_ratio
                            except:
                                pass
                        
                        # ë°°ë‹¹ìˆ˜ìµë¥ 
                        elif 'ë°°ë‹¹ìˆ˜ìµë¥ ' in key or 'ë¶„ë°°ê¸ˆìˆ˜ìµë¥ ' in key:
                            try:
                                dividend_yield = float(value.replace('%', '').replace(',', ''))
                                etf_info['dividend_yield'] = dividend_yield
                            except:
                                pass
                        
                        # ìˆœìì‚°ê°€ì¹˜ (NAV)
                        elif 'NAV' in key or 'ìˆœìì‚°ê°€ì¹˜' in key:
                            try:
                                nav = float(value.replace(',', '').replace('ì›', ''))
                                etf_info['nav'] = nav
                            except:
                                pass
                        
                        # ì¶”ì ì˜¤ì°¨
                        elif 'ì¶”ì ì˜¤ì°¨' in key:
                            try:
                                tracking_error = float(value.replace('%', '').replace(',', ''))
                                etf_info['tracking_error'] = tracking_error
                            except:
                                pass
            
            # ì¶”ê°€ë¡œ ETF ê¸°ë³¸ ì •ë³´ ì„¹ì…˜ í™•ì¸
            etf_summary = soup.select_one('.etf_summary, .etf_info')
            if etf_summary:
                summary_text = etf_summary.get_text()
                
                # ìš´ìš©ë³´ìˆ˜ íŒ¨í„´ ë§¤ì¹­
                import re
                expense_match = re.search(r'ìš´ìš©ë³´ìˆ˜[:\s]*([0-9.]+)%', summary_text)
                if expense_match and 'expense_ratio' not in etf_info:
                    etf_info['expense_ratio'] = float(expense_match.group(1))
                
                # ë°°ë‹¹ìˆ˜ìµë¥  íŒ¨í„´ ë§¤ì¹­
                dividend_match = re.search(r'ë°°ë‹¹ìˆ˜ìµë¥ [:\s]*([0-9.]+)%', summary_text)
                if dividend_match and 'dividend_yield' not in etf_info:
                    etf_info['dividend_yield'] = float(dividend_match.group(1))
            
            if etf_info:
                logger.debug(f"ë„¤ì´ë²„ ìŠ¤í¬ë˜í•‘ ETF {ticker} ì •ë³´ ì¡°íšŒ ì„±ê³µ: {etf_info}")
            else:
                logger.debug(f"ë„¤ì´ë²„ ìŠ¤í¬ë˜í•‘ ETF {ticker} ì •ë³´ ì—†ìŒ")
            
            return etf_info
            
        except Exception as e:
            logger.debug(f"ë„¤ì´ë²„ ìŠ¤í¬ë˜í•‘ ETF {ticker} ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    def get_comprehensive_etf_details(self, ticker: str) -> Dict:
        """ë³µí•© ì „ëµìœ¼ë¡œ ETF ìƒì„¸ ì •ë³´ ì¡°íšŒ (API + ìŠ¤í¬ë˜í•‘ + ì •ì ë°ì´í„°)"""
        
        # ìºì‹œ í™•ì¸
        cache_key = f"etf_details_{ticker}"
        cached_data = self._get_cache(cache_key)
        if cached_data:
            return cached_data
        
        etf_details = {
            'expense_ratio': 0.0,
            'dividend_yield': 0.0,
            'nav': 0.0,
            'tracking_error': 0.0
        }
        
        # 1ìˆœìœ„: ë„¤ì´ë²„ ê¸ˆìœµ API ì‹œë„
        try:
            api_data = self.get_naver_etf_info(ticker)
            if api_data:
                etf_details.update(api_data)
                logger.debug(f"ETF {ticker} API ë°ì´í„° ì‚¬ìš©")
        except Exception as e:
            logger.debug(f"ETF {ticker} API ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        # 2ìˆœìœ„: ì›¹ ìŠ¤í¬ë˜í•‘ (APIì—ì„œ ëª» ê°€ì ¸ì˜¨ ì •ë³´ë§Œ)
        missing_fields = [k for k, v in etf_details.items() if v == 0.0]
        if missing_fields:
            try:
                scraped_data = self.scrape_naver_etf_info(ticker)
                for field in missing_fields:
                    if field in scraped_data and scraped_data[field] > 0:
                        etf_details[field] = scraped_data[field]
                        
                if scraped_data:
                    logger.debug(f"ETF {ticker} ìŠ¤í¬ë˜í•‘ ë°ì´í„°ë¡œ ë³´ì™„")
            except Exception as e:
                logger.debug(f"ETF {ticker} ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
        
        # 3ìˆœìœ„: ì •ì  ë°ì´í„° (ì—¬ì „íˆ ë¹ˆ ê°’ì´ ìˆìœ¼ë©´)
        static_data = self._get_static_etf_data(ticker)
        for field, value in etf_details.items():
            if value == 0.0 and field in static_data:
                etf_details[field] = static_data[field]
        
        # ìºì‹œì— ì €ì¥ (6ì‹œê°„)
        self.cache[cache_key] = (time.time(), etf_details)
        
        logger.debug(f"ETF {ticker} ìµœì¢… ìƒì„¸ì •ë³´: {etf_details}")
        return etf_details
    
    def _get_static_etf_data(self, ticker: str) -> Dict:
        """ì •ì  ETF ë°ì´í„° (ë°±ì—…ìš©)"""
        static_data = {
            # KODEX ì‹œë¦¬ì¦ˆ
            '069500': {'expense_ratio': 0.15, 'dividend_yield': 2.1, 'tracking_error': 0.05},  # KODEX 200
            '069660': {'expense_ratio': 0.16, 'dividend_yield': 1.8, 'tracking_error': 0.08},  # KODEX ì½”ìŠ¤ë‹¥150
            '114260': {'expense_ratio': 0.15, 'dividend_yield': 3.2, 'tracking_error': 0.03},  # KODEX êµ­ê³ ì±„10ë…„
            '133690': {'expense_ratio': 0.30, 'dividend_yield': 0.9, 'tracking_error': 0.12},  # KODEX ë‚˜ìŠ¤ë‹¥100
            '195930': {'expense_ratio': 0.25, 'dividend_yield': 2.3, 'tracking_error': 0.15},  # KODEX ì„ ì§„êµ­MSCI
            '132030': {'expense_ratio': 0.30, 'dividend_yield': 0.0, 'tracking_error': 0.20},  # KODEX ê³¨ë“œì„ ë¬¼(H)
            '189400': {'expense_ratio': 0.30, 'dividend_yield': 4.5, 'tracking_error': 0.25},  # KODEX ë¯¸êµ­ë¦¬ì¸ 
            
            # TIGER ì‹œë¦¬ì¦ˆ
            '102110': {'expense_ratio': 0.15, 'dividend_yield': 2.0, 'tracking_error': 0.06},  # TIGER 200
            '148020': {'expense_ratio': 0.16, 'dividend_yield': 1.7, 'tracking_error': 0.09},  # TIGER ì½”ìŠ¤ë‹¥150
            '360750': {'expense_ratio': 0.17, 'dividend_yield': 1.8, 'tracking_error': 0.10},  # TIGER ë¯¸êµ­S&P500
            '360200': {'expense_ratio': 0.30, 'dividend_yield': 0.8, 'tracking_error': 0.11},  # TIGER ë¯¸êµ­ë‚˜ìŠ¤ë‹¥100
            '381170': {'expense_ratio': 0.45, 'dividend_yield': 2.5, 'tracking_error': 0.30},  # TIGER ì°¨ì´ë‚˜CSI300
            
            # ARIRANG ì‹œë¦¬ì¦ˆ
            '152100': {'expense_ratio': 0.16, 'dividend_yield': 2.2, 'tracking_error': 0.07},  # ARIRANG 200
            '174360': {'expense_ratio': 0.25, 'dividend_yield': 3.8, 'tracking_error': 0.18},  # ARIRANG ê³ ë°°ë‹¹ì£¼
            
            # ê¸°íƒ€
            '130730': {'expense_ratio': 0.15, 'dividend_yield': 3.5, 'tracking_error': 0.02},  # KOSEF ë‹¨ê¸°ìê¸ˆ
            '139660': {'expense_ratio': 0.35, 'dividend_yield': 1.2, 'tracking_error': 0.20},  # TIGER 200IT
        }
        
        return static_data.get(ticker, {
            'expense_ratio': 0.25,  # ê¸°ë³¸ê°’
            'dividend_yield': 1.5,  # ê¸°ë³¸ê°’
            'tracking_error': 0.15  # ê¸°ë³¸ê°’
        })
    
    def _is_etf_ticker(self, ticker: str) -> bool:
        """í‹°ì»¤ê°€ ETFì¸ì§€ í™•ì¸"""
        try:
            # ETF í‹°ì»¤ íŒ¨í„´ í™•ì¸
            # í•œêµ­ ETFëŠ” ë³´í†µ íŠ¹ì • íŒ¨í„´ì„ ê°€ì§
            etf_patterns = [
                # KODEX, TIGER, ARIRANG ë“±ì˜ ETF ì½”ë“œ íŒ¨í„´
                '069', '102', '114', '117', '130', '132', '133', '139', 
                '148', '152', '174', '189', '195', '229', '251', '305',
                '329', '351', '360', '381', '395', '407', '427', '449',
                '458', '472', '476', '495', '496'
            ]
            
            # í‹°ì»¤ ì• 3ìë¦¬ê°€ ETF íŒ¨í„´ì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸
            ticker_prefix = ticker[:3]
            return ticker_prefix in etf_patterns
            
        except:
            return False
    
    def _get_etf_name(self, ticker: str) -> str:
        """ETF ì´ë¦„ ì¡°íšŒ (í™•ì¥ëœ ë§¤í•‘)"""
        try:
            # í™•ì¥ëœ ETF ì´ë¦„ ë§¤í•‘
            etf_names = {
                # KODEX ì‹œë¦¬ì¦ˆ (069xxx)
                '069500': 'KODEX 200',
                '069660': 'KODEX ì½”ìŠ¤ë‹¥150',
                
                # TIGER ì‹œë¦¬ì¦ˆ (102xxx)
                '102110': 'TIGER 200',
                '102860': 'TIGER 200ì»¤ë²„ë“œì½œ',
                
                # KODEX ì±„ê¶Œ ì‹œë¦¬ì¦ˆ (114xxx)
                '114260': 'KODEX êµ­ê³ ì±„10ë…„',
                '114470': 'KODEX êµ­ê³ ì±„30ë…„',
                
                # KOSEF ì‹œë¦¬ì¦ˆ (130xxx)
                '130730': 'KOSEF ë‹¨ê¸°ìê¸ˆ',
                
                # KODEX ì›ìì¬ ì‹œë¦¬ì¦ˆ (132xxx)
                '132030': 'KODEX ê³¨ë“œì„ ë¬¼(H)',
                
                # KODEX í•´ì™¸ ì‹œë¦¬ì¦ˆ (133xxx)
                '133690': 'KODEX ë‚˜ìŠ¤ë‹¥100',
                
                # TIGER ì½”ìŠ¤ë‹¥ ì‹œë¦¬ì¦ˆ (148xxx)
                '148020': 'TIGER ì½”ìŠ¤ë‹¥150',
                
                # ARIRANG ì‹œë¦¬ì¦ˆ (152xxx)
                '152100': 'ARIRANG 200',
                '152500': 'ARIRANG ì½”ìŠ¤í”¼',
                
                # KODEX ë¦¬ì¸  ì‹œë¦¬ì¦ˆ (189xxx)
                '189400': 'KODEX ë¯¸êµ­ë¦¬ì¸ ',
                
                # KODEX ì„ ì§„êµ­ ì‹œë¦¬ì¦ˆ (195xxx)
                '195930': 'KODEX ì„ ì§„êµ­MSCI',
                
                # TIGER í•´ì™¸ ì‹œë¦¬ì¦ˆ (360xxx)
                '360750': 'TIGER ë¯¸êµ­S&P500',
                '360200': 'TIGER ë¯¸êµ­ë‚˜ìŠ¤ë‹¥100',
                
                # TIGER ì‹ í¥êµ­ ì‹œë¦¬ì¦ˆ (381xxx)
                '381170': 'TIGER ì°¨ì´ë‚˜CSI300',
                
                # ê¸°íƒ€ ì•ˆì „í•œ ETFë“¤
                '174360': 'ARIRANG ê³ ë°°ë‹¹ì£¼',
                '139660': 'TIGER 200IT',
                
                # âš ï¸ ë¬¸ì œ ì¢…ëª©ë“¤ (ì²˜ë¦¬ëŠ” í•˜ë˜ ì£¼ì˜)
                '427120': 'KBSTAR ì¤‘ê¸°ì±„ê¶Œ',
                '495710': 'TIMEFOLIO Koreaí”ŒëŸ¬ìŠ¤ë°°ë‹¹ì•¡í‹°ë¸Œ',
            }
            
            return etf_names.get(ticker, f'ETF_{ticker}')
            
        except:
            return f'ETF_{ticker}'
    
    def _is_safe_etf(self, ticker: str) -> bool:
        """ETFê°€ ì•ˆì „í•œì§€ í™•ì¸ (ì£¼ìš” ìš´ìš©ì‚¬ì˜ ì•ˆì •ì ì¸ ETFë§Œ)"""
        try:
            # ì•ˆì „í•œ ETF íŒ¨í„´ë“¤ (ì£¼ìš” 3ê°œ ìš´ìš©ì‚¬ì˜ ëŒ€í‘œ ETFë“¤)
            safe_patterns = {
                # KODEX (ì‚¼ì„±ìì‚°ìš´ìš©) - ê°€ì¥ ì•ˆì •ì 
                '069': ['069500', '069660'],  # ë©”ì¸ ì¸ë±ìŠ¤ ETF
                '114': ['114260', '114470'],  # êµ­ì±„ ETF
                '130': ['130730'],            # ë‹¨ê¸°ìê¸ˆ ETF
                '132': ['132030'],            # ì›ìì¬ ETF
                '133': ['133690'],            # ë‚˜ìŠ¤ë‹¥ ETF
                '189': ['189400'],            # ë¦¬ì¸  ETF
                '195': ['195930'],            # ì„ ì§„êµ­ ETF
                
                # TIGER (ë¯¸ë˜ì—ì…‹ìì‚°ìš´ìš©) - ì•ˆì •ì 
                '102': ['102110', '102860'],  # ë©”ì¸ ì¸ë±ìŠ¤ ETF
                '148': ['148020'],            # ì½”ìŠ¤ë‹¥ ETF
                '360': ['360750', '360200'],  # ë¯¸êµ­ ETF
                '381': ['381170'],            # ì¤‘êµ­ ETF
                
                # ARIRANG (í•œêµ­íˆ¬ìì‹ íƒìš´ìš©) - ì•ˆì •ì 
                '152': ['152100', '152500'],  # ì¸ë±ìŠ¤ ETF
                '174': ['174360'],            # ë°°ë‹¹ ETF
                
                # ê¸°íƒ€ ì•ˆì •ì ì¸ ìš´ìš©ì‚¬
                '139': ['139660'],            # TIGER IT ETF
            }
            
            # í‹°ì»¤ ì• 3ìë¦¬ë¡œ íŒ¨í„´ í™•ì¸
            prefix = ticker[:3]
            
            if prefix in safe_patterns:
                # í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ” ETFë§Œ í—ˆìš©
                allowed_tickers = safe_patterns[prefix]
                return ticker in allowed_tickers
            
            return False  # íŒ¨í„´ì— ì—†ìœ¼ë©´ ì•ˆì „í•˜ì§€ ì•ŠìŒ
            
        except:
            return False
    
    def _classify_etf_category(self, ticker: str) -> str:
        """ETF ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ (í™•ì¥ëœ íŒ¨í„´)"""
        # ë” ìƒì„¸í•œ ë¶„ë¥˜ íŒ¨í„´
        category_patterns = {
            'domestic_equity': [
                '069500', '102110', '229200', '152100',  # ëŒ€í˜•ì£¼
                '069660', '148020', '251350',            # ì½”ìŠ¤ë‹¥
                '139660', '174360',                      # ì„¹í„°/í…Œë§ˆ
            ],
            'foreign_equity': [
                '360750', '133690', '195930',            # ì„ ì§„êµ­
                '381170', '381180',                      # ì‹ í¥êµ­
            ],
            'bonds': [
                '114260', '305080', '130730',            # êµ­ë‚´ ì±„ê¶Œ
                '329750', '329200',                      # í•´ì™¸ ì±„ê¶Œ
            ],
            'alternatives': [
                '132030', '351590',                      # ì›ìì¬
                '189400', '329200',                      # ë¦¬ì¸ 
            ],
            'leveraged_inverse': [
                '117460', '251350',                      # ë ˆë²„ë¦¬ì§€/ì¸ë²„ìŠ¤
            ]
        }
        
        for category, tickers in category_patterns.items():
            if ticker in tickers:
                return category
        
        # í‹°ì»¤ íŒ¨í„´ìœ¼ë¡œ ì¶”ê°€ ë¶„ë¥˜
        if ticker.startswith('49'):  # ì¼ë¶€ íŠ¹ìˆ˜ ETF
            return 'special'
        
        # ê¸°ë³¸ê°’
        return 'domestic_equity'
    
    def _get_default_etf_list(self) -> List[Dict]:
        """ê¸°ë³¸ ETF ë¦¬ìŠ¤íŠ¸ (pykrx ì—†ì„ ë•Œ)"""
        default_etfs = [
            {
                'code': '069500',
                'name': 'KODEX 200',
                'category': 'domestic_equity',
                'market_price': 28400,
                'aum': 20000,
                'volume': 5000000,
                'last_updated': datetime.now().isoformat()
            },
            {
                'code': '360750',
                'name': 'TIGER ë¯¸êµ­S&P500',
                'category': 'foreign_equity',
                'market_price': 15800,
                'aum': 25000,
                'volume': 2000000,
                'last_updated': datetime.now().isoformat()
            },
            {
                'code': '114260',
                'name': 'KODEX êµ­ê³ ì±„10ë…„',
                'category': 'bonds',
                'market_price': 108500,
                'aum': 3000,
                'volume': 500000,
                'last_updated': datetime.now().isoformat()
            },
            {
                'code': '133690',
                'name': 'KODEX ë‚˜ìŠ¤ë‹¥100',
                'category': 'foreign_equity',
                'market_price': 22100,
                'aum': 8000,
                'volume': 1500000,
                'last_updated': datetime.now().isoformat()
            },
            {
                'code': '102110',
                'name': 'TIGER 200',
                'category': 'domestic_equity',
                'market_price': 28350,
                'aum': 15000,
                'volume': 3000000,
                'last_updated': datetime.now().isoformat()
            },
            {
                'code': '427120',
                'name': 'KBSTAR ì¤‘ê¸°',
                'category': 'bonds',
                'market_price': 98500,
                'aum': 1200,
                'volume': 200000,
                'last_updated': datetime.now().isoformat()
            }
        ]
        
        logger.info(f"ê¸°ë³¸ ETF ë¦¬ìŠ¤íŠ¸ ë°˜í™˜: {len(default_etfs)}ê°œ")
        return default_etfs
    
    def fetch_etf_price_data(self, ticker: str, period: str = "1m") -> pd.DataFrame:
        """ETF ê°€ê²© ë°ì´í„° ì¡°íšŒ (ì•ˆì „í•œ ì»¬ëŸ¼ ì²˜ë¦¬)"""
        cache_key = self._get_cache_key("price", ticker, period)
        cached_data = self._get_cache(cache_key)
        if cached_data is not None:
            return cached_data
        
        if not PYKRX_AVAILABLE:
            logger.warning(f"pykrx ì—†ìŒ - {ticker} ë”ë¯¸ ë°ì´í„° ë°˜í™˜")
            return self._generate_dummy_price_data(ticker, period)
        
        try:
            # ê¸°ê°„ ê³„ì‚°
            end_date = datetime.now()
            
            if period == "1d":
                start_date = end_date - timedelta(days=1)
            elif period == "1w":
                start_date = end_date - timedelta(days=7)
            elif period == "1m":
                start_date = end_date - timedelta(days=30)
            elif period == "3m":
                start_date = end_date - timedelta(days=90)
            elif period == "1y":
                start_date = end_date - timedelta(days=365)
            else:
                start_date = end_date - timedelta(days=30)
            
            # ì˜ì—…ì¼ë¡œ ì¡°ì •
            start_date_str = self.get_last_business_day(start_date)
            end_date_str = self.get_last_business_day(end_date)
            
            logger.info(f"ETF {ticker} ê°€ê²© ë°ì´í„° ì¡°íšŒ: {start_date_str} ~ {end_date_str}")
            
            self._rate_limit()
            
            # pykrxë¡œ OHLCV ë°ì´í„° ì¡°íšŒ
            df = stock.get_market_ohlcv_by_date(start_date_str, end_date_str, ticker)
            
            if df.empty:
                logger.warning(f"ETF {ticker} ê°€ê²© ë°ì´í„° ì—†ìŒ")
                return self._generate_dummy_price_data(ticker, period)
            
            # ì•ˆì „í•œ ì»¬ëŸ¼ ì²˜ë¦¬
            logger.debug(f"ETF {ticker} ì›ë³¸ ì»¬ëŸ¼: {list(df.columns)}")
            
            # ì»¬ëŸ¼ëª…ì„ ì•ˆì „í•˜ê²Œ ë§¤í•‘
            column_mapping = {}
            original_columns = list(df.columns)
            
            # í•œê¸€ ì»¬ëŸ¼ëª… ì²˜ë¦¬
            korean_to_english = {
                'ì‹œê°€': 'open',
                'ê³ ê°€': 'high', 
                'ì €ê°€': 'low',
                'ì¢…ê°€': 'close',
                'ê±°ë˜ëŸ‰': 'volume',
                'ê±°ë˜ëŒ€ê¸ˆ': 'amount'
            }
            
            # í‘œì¤€ ì˜ì–´ ì»¬ëŸ¼ëª… ì²˜ë¦¬
            standard_columns = ['open', 'high', 'low', 'close', 'volume']
            
            # ì»¬ëŸ¼ ë§¤í•‘ ìƒì„±
            for i, col in enumerate(original_columns):
                if col in korean_to_english:
                    column_mapping[col] = korean_to_english[col]
                elif col.lower() in standard_columns:
                    column_mapping[col] = col.lower()
                elif i < len(standard_columns):
                    # ìˆœì„œë¡œ ë§¤í•‘ (OHLCV ìˆœì„œ ê°€ì •)
                    column_mapping[col] = standard_columns[i]
            
            # ì»¬ëŸ¼ëª… ë³€ê²½
            df_processed = df.rename(columns=column_mapping)
            
            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
            required_columns = ['open', 'high', 'low', 'close', 'volume']
            available_columns = [col for col in required_columns if col in df_processed.columns]
            
            if len(available_columns) < 4:  # ìµœì†Œ OHLCëŠ” ìˆì–´ì•¼ í•¨
                logger.warning(f"ETF {ticker} ì¶©ë¶„í•œ ê°€ê²© ë°ì´í„° ì»¬ëŸ¼ ì—†ìŒ: {available_columns}")
                return self._generate_dummy_price_data(ticker, period)
            
            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
            df_final = df_processed[available_columns].copy()
            
            # ì¸ë±ìŠ¤ë¥¼ date ì»¬ëŸ¼ìœ¼ë¡œ ë³€í™˜ (ì•ˆì „í•œ ë°©ì‹)
            df_final = df_final.reset_index()
            
            # ë‚ ì§œ ì»¬ëŸ¼ ì´ë¦„ í†µì¼ (ë‹¤ì–‘í•œ ê²½ìš°ë¥¼ ì²˜ë¦¬)
            date_column_candidates = ['index', 'ë‚ ì§œ', 'date', 'Date', 'DATE']
            date_column = None
            
            for candidate in date_column_candidates:
                if candidate in df_final.columns:
                    date_column = candidate
                    break
            
            if date_column:
                df_final = df_final.rename(columns={date_column: 'date'})
            else:
                # ë‚ ì§œ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì¸ë±ìŠ¤ë¥¼ ë‚ ì§œë¡œ ìƒì„±
                logger.warning(f"ETF {ticker} ë‚ ì§œ ì»¬ëŸ¼ ì—†ìŒ, ì¸ë±ìŠ¤ë¡œ ìƒì„±")
                dates = pd.date_range(end=end_date, periods=len(df_final), freq='D')
                business_dates = [d for d in dates if d.weekday() < 5]
                if len(business_dates) >= len(df_final):
                    df_final['date'] = business_dates[:len(df_final)]
                else:
                    df_final['date'] = dates[:len(df_final)]
            
            # ë‚ ì§œ í˜•ì‹ ë³€í™˜ (ì•ˆì „í•˜ê²Œ)
            if 'date' in df_final.columns:
                try:
                    df_final['date'] = pd.to_datetime(df_final['date'])
                except Exception as e:
                    logger.warning(f"ETF {ticker} ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨: {e}")
                    # ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨ì‹œ í˜„ì¬ ë‚ ì§œë¶€í„° ì—­ìˆœìœ¼ë¡œ ìƒì„±
                    dates = pd.date_range(end=end_date, periods=len(df_final), freq='D')
                    df_final['date'] = [d for d in dates if d.weekday() < 5][:len(df_final)]
            
            # ìˆ˜ìµë¥  ê³„ì‚° (close ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°ë§Œ)
            if 'close' in df_final.columns:
                df_final['returns'] = df_final['close'].pct_change().fillna(0)
            
            # ë³¼ë¥¨ì´ ì—†ìœ¼ë©´ ë”ë¯¸ê°’ ì¶”ê°€
            if 'volume' not in df_final.columns:
                df_final['volume'] = np.random.randint(10000, 100000, len(df_final))
            
            # ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬
            column_order = ['date', 'open', 'high', 'low', 'close', 'volume', 'returns']
            final_columns = [col for col in column_order if col in df_final.columns]
            df_final = df_final[final_columns]
            
            logger.info(f"ETF {ticker} ê°€ê²© ë°ì´í„° ì¡°íšŒ ì™„ë£Œ: {len(df_final)}ê±´, ì»¬ëŸ¼: {list(df_final.columns)}")
            
            # ìºì‹œì— ì €ì¥
            self._set_cache(cache_key, df_final)
            
            return df_final
            
        except Exception as e:
            logger.error(f"ETF {ticker} ê°€ê²© ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return self._generate_dummy_price_data(ticker, period)
    
    def _generate_dummy_price_data(self, ticker: str, period: str) -> pd.DataFrame:
        """ë”ë¯¸ ê°€ê²© ë°ì´í„° ìƒì„±"""
        # ê¸°ê°„ì— ë”°ë¥¸ ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜
        period_days = {
            "1d": 1,
            "1w": 7,
            "1m": 30,
            "3m": 90,
            "1y": 365
        }
        
        days = period_days.get(period, 30)
        
        # ê¸°ë³¸ ê°€ê²© ì„¤ì •
        base_prices = {
            '069500': 28400,
            '360750': 15800,
            '114260': 108500,
            '133690': 22100,
            '102110': 28350,
            '427120': 98500,  # KBSTAR ì¤‘ê¸° ì±„ê¶Œ
            '495710': 12000,  # TIMEFOLIO Koreaí”ŒëŸ¬ìŠ¤ë°°ë‹¹ì•¡í‹°ë¸Œ
        }
        
        base_price = base_prices.get(ticker, 10000)
        
        # ë”ë¯¸ ë°ì´í„° ìƒì„±
        end_date = datetime.now()
        dates = pd.date_range(end=end_date, periods=days, freq='D')
        
        # ì£¼ë§ ì œê±° (ì˜ì—…ì¼ë§Œ)
        business_dates = [d for d in dates if d.weekday() < 5]
        if not business_dates:
            business_dates = [end_date]
        
        # ëœë¤ ê°€ê²© ë³€ë™ (ì‹œë“œ ê³ ì •ìœ¼ë¡œ ì¼ê´€ì„± ìœ ì§€)
        np.random.seed(hash(ticker) % 1000)
        
        # ETF íƒ€ì…ì— ë”°ë¥¸ ë³€ë™ì„± ì¡°ì •
        if ticker in ['114260', '427120']:  # ì±„ê¶Œ ETFëŠ” ë³€ë™ì„± ë‚®ê²Œ
            volatility = 0.005
        elif ticker in ['069500', '102110']:  # ëŒ€í˜•ì£¼ ETF
            volatility = 0.015
        else:  # ê¸°íƒ€ ETF
            volatility = 0.02
            
        returns = np.random.normal(0.0005, volatility, len(business_dates))  # ë‚®ì€ í‰ê·  ìˆ˜ìµë¥ 
        
        prices = [base_price]
        for r in returns[1:]:
            prices.append(max(prices[-1] * (1 + r), 100))  # ìµœì†Œ 100ì›
        
        # ë¶€ì¡±í•œ ë°ì´í„° í¬ì¸íŠ¸ ì±„ìš°ê¸°
        while len(prices) < len(business_dates):
            prices.append(prices[-1])
        
        # OHLCV ë°ì´í„° ìƒì„±
        data = []
        for i, (date, price) in enumerate(zip(business_dates, prices)):
            daily_volatility = abs(np.random.normal(0, volatility/2))
            
            open_price = price * (1 + np.random.normal(0, 0.003))
            high_price = max(open_price, price) * (1 + daily_volatility)
            low_price = min(open_price, price) * (1 - daily_volatility)
            close_price = price
            
            # ê±°ë˜ëŸ‰ë„ ETF íƒ€ì…ì— ë”°ë¼ ì¡°ì •
            if ticker in ['069500', '102110', '360750']:  # ëŒ€í˜• ETF
                volume = np.random.randint(500000, 2000000)
            elif ticker in ['114260', '427120']:  # ì±„ê¶Œ ETF
                volume = np.random.randint(50000, 300000)
            else:  # ê¸°íƒ€ ETF
                volume = np.random.randint(100000, 800000)
            
            data.append({
                'date': date,
                'open': round(open_price, 0),
                'high': round(high_price, 0),
                'low': round(low_price, 0),
                'close': round(close_price, 0),
                'volume': volume
            })
        
        # DataFrame ìƒì„±
        df = pd.DataFrame(data)
        df['returns'] = df['close'].pct_change().fillna(0)
        
        logger.info(f"ETF {ticker} ë”ë¯¸ ë°ì´í„° ìƒì„±: {len(df)}ê±´ (ê¸°ì¤€ê°€: {base_price:,}ì›)")
        
        return df
    
    def calculate_performance_metrics(self, price_data: pd.DataFrame) -> Dict:
        """ì„±ê³¼ ì§€í‘œ ê³„ì‚°"""
        if price_data.empty:
            return {'data_points': 0}
        
        try:
            returns = price_data['returns'].dropna() if 'returns' in price_data.columns else pd.Series()
            
            if len(returns) == 0 or 'close' not in price_data.columns:
                return {'data_points': len(price_data)}
            
            # ê¸°ë³¸ ì„±ê³¼ ì§€í‘œ ê³„ì‚°
            metrics = {
                'data_points': len(price_data),
                'total_return': (price_data['close'].iloc[-1] / price_data['close'].iloc[0] - 1) * 100,
                'volatility': returns.std() * np.sqrt(252) * 100 if len(returns) > 1 else 0,  # ì—°í™˜ì‚° ë³€ë™ì„±
                'sharpe_ratio': (returns.mean() / returns.std() * np.sqrt(252)) if returns.std() > 0 else 0,
                'max_drawdown': self._calculate_max_drawdown(price_data['close']),
                'avg_volume': price_data['volume'].mean() if 'volume' in price_data.columns else 0,
                'current_price': price_data['close'].iloc[-1]
            }
            
            return metrics
            
        except Exception as e:
            logger.error(f"ì„±ê³¼ ì§€í‘œ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {'data_points': len(price_data)}
    
    def _calculate_max_drawdown(self, prices: pd.Series) -> float:
        """ìµœëŒ€ ë‚™í­ ê³„ì‚°"""
        try:
            cumulative = (1 + prices.pct_change()).cumprod()
            running_max = cumulative.expanding().max()
            drawdown = (cumulative - running_max) / running_max
            return abs(drawdown.min()) * 100
        except:
            return 0.0
    
    def fetch_etf_info(self, ticker: str) -> Dict:
        """ETF ì¶”ê°€ ì •ë³´ ì¡°íšŒ"""
        cache_key = self._get_cache_key("info", ticker)
        cached_data = self._get_cache(cache_key)
        if cached_data:
            return cached_data
        
        try:
            last_business_day = self.get_last_business_day()
            
            info = {
                'ticker': ticker,
                'current_price': 0,
                'nav': 0,
                'premium_discount': 0,
                'volume': 0,
                'last_updated': datetime.now().isoformat()
            }
            
            if PYKRX_AVAILABLE:
                try:
                    self._rate_limit()
                    
                    # ìµœì‹  ê°€ê²© ì •ë³´
                    price_data = stock.get_market_ohlcv_by_date(last_business_day, last_business_day, ticker)
                    if not price_data.empty:
                        last_row = price_data.iloc[-1]
                        
                        # ì•ˆì „í•œ ì»¬ëŸ¼ ì ‘ê·¼
                        if 'ì¢…ê°€' in price_data.columns:
                            info['current_price'] = float(last_row['ì¢…ê°€'])
                        elif len(price_data.columns) >= 4:
                            info['current_price'] = float(last_row.iloc[3])  # ì¢…ê°€ ìœ„ì¹˜
                        
                        if 'ê±°ë˜ëŸ‰' in price_data.columns:
                            info['volume'] = int(last_row['ê±°ë˜ëŸ‰'])
                        elif len(price_data.columns) >= 5:
                            info['volume'] = int(last_row.iloc[4])  # ê±°ë˜ëŸ‰ ìœ„ì¹˜
                    
                    # ETF íŠ¹í™” ì •ë³´ (ê°€ëŠ¥í•œ ê²½ìš°)
                    info['nav'] = info['current_price']  # ì„ì‹œë¡œ í˜„ì¬ê°€ ì‚¬ìš©
                    info['premium_discount'] = 0  # ê³„ì‚° í•„ìš”
                        
                except Exception as e:
                    logger.debug(f"ETF {ticker} ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
                    # ê¸°ë³¸ê°’ ì‚¬ìš©
                    info['current_price'] = 10000
                    info['nav'] = 10000
            
            # ìºì‹œì— ì €ì¥
            self._set_cache(cache_key, info)
            
            return info
            
        except Exception as e:
            logger.error(f"ETF {ticker} ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                'ticker': ticker,
                'current_price': 10000,
                'nav': 10000,
                'premium_discount': 0,
                'volume': 0,
                'last_updated': datetime.now().isoformat()
            }
    
    def update_etf_database(self, etf_list: List[Dict]) -> bool:
        """ETF ì •ë³´ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì—…ë°ì´íŠ¸ (í™•ì¥ëœ ìŠ¤í‚¤ë§ˆ)"""
        try:
            conn = sqlite3.connect(self.db_path)
            
            # í™•ì¥ëœ í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ìƒì„± (ìƒì„¸ ì •ë³´ ì»¬ëŸ¼ ì¶”ê°€)
            conn.execute('''
                CREATE TABLE IF NOT EXISTS etf_info (
                    code TEXT PRIMARY KEY,
                    name TEXT NOT NULL,
                    category TEXT,
                    market_price REAL DEFAULT 0,
                    aum REAL DEFAULT 0,
                    volume INTEGER DEFAULT 0,
                    expense_ratio REAL DEFAULT 0,
                    dividend_yield REAL DEFAULT 0,
                    nav REAL DEFAULT 0,
                    tracking_error REAL DEFAULT 0,
                    is_active INTEGER DEFAULT 1,
                    last_updated TEXT,
                    created_at TEXT DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # ê¸°ì¡´ í…Œì´ë¸”ì— ìƒˆ ì»¬ëŸ¼ë“¤ ì¶”ê°€ (ì•ˆì „í•œ ALTER TABLE)
            try:
                cursor = conn.execute("PRAGMA table_info(etf_info)")
                columns = [column[1] for column in cursor.fetchall()]
                
                new_columns = {
                    'expense_ratio': 'REAL DEFAULT 0',
                    'dividend_yield': 'REAL DEFAULT 0', 
                    'nav': 'REAL DEFAULT 0',
                    'tracking_error': 'REAL DEFAULT 0',
                    'is_active': 'INTEGER DEFAULT 1',
                    'created_at': 'TEXT DEFAULT CURRENT_TIMESTAMP'
                }
                
                for col_name, col_type in new_columns.items():
                    if col_name not in columns:
                        conn.execute(f'ALTER TABLE etf_info ADD COLUMN {col_name} {col_type}')
                        logger.info(f"{col_name} ì»¬ëŸ¼ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤")
                        
            except Exception as e:
                logger.debug(f"ì»¬ëŸ¼ ì¶”ê°€ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ ê°€ëŠ¥): {e}")
            
            updated_count = 0
            current_time = datetime.now().isoformat()
            
            for etf in etf_list:
                try:
                    conn.execute('''
                        INSERT OR REPLACE INTO etf_info 
                        (code, name, category, market_price, aum, volume, 
                         expense_ratio, dividend_yield, nav, tracking_error,
                         is_active, last_updated, created_at)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    ''', (
                        etf['code'],
                        etf['name'],
                        etf.get('category', 'unknown'),
                        etf.get('market_price', 0),
                        etf.get('aum', 0),
                        etf.get('volume', 0),
                        etf.get('expense_ratio', 0.0),
                        etf.get('dividend_yield', 0.0),
                        etf.get('nav', 0.0),
                        etf.get('tracking_error', 0.0),
                        1,  # is_active = 1 (í™œì„± ìƒíƒœ)
                        etf['last_updated'],
                        current_time  # created_at
                    ))
                    updated_count += 1
                except Exception as e:
                    logger.error(f"ETF {etf.get('code', 'unknown')} ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
                    continue
            
            conn.commit()
            conn.close()
            
            logger.info(f"ETF ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {updated_count}ê°œ (ìƒì„¸ì •ë³´ í¬í•¨)")
            return True
            
        except Exception as e:
            logger.error(f"ETF ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def create_database_schema(self) -> bool:
        """ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ìƒì„± (ì „ì²´ ìŠ¤í‚¤ë§ˆ)"""
        try:
            conn = sqlite3.connect(self.db_path)
            
            # ETF ê¸°ë³¸ ì •ë³´ í…Œì´ë¸”
            conn.execute('''
                CREATE TABLE IF NOT EXISTS etf_info (
                    code TEXT PRIMARY KEY,
                    name TEXT NOT NULL,
                    category TEXT,
                    market_price REAL DEFAULT 0,
                    aum REAL DEFAULT 0,
                    volume INTEGER DEFAULT 0,
                    is_active INTEGER DEFAULT 1,
                    last_updated TEXT,
                    created_at TEXT DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # ETF ê°€ê²© íˆìŠ¤í† ë¦¬ í…Œì´ë¸” (ì¶”ê°€)
            conn.execute('''
                CREATE TABLE IF NOT EXISTS etf_prices (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    code TEXT NOT NULL,
                    date TEXT NOT NULL,
                    open_price REAL,
                    high_price REAL,
                    low_price REAL,
                    close_price REAL,
                    volume INTEGER,
                    created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (code) REFERENCES etf_info(code),
                    UNIQUE(code, date)
                )
            ''')
            
            # í¬íŠ¸í´ë¦¬ì˜¤ í…Œì´ë¸” (ì¶”ê°€)
            conn.execute('''
                CREATE TABLE IF NOT EXISTS portfolios (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    name TEXT NOT NULL,
                    description TEXT,
                    user_id TEXT,
                    is_active INTEGER DEFAULT 1,
                    created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                    updated_at TEXT DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„± í…Œì´ë¸” (ì¶”ê°€)
            conn.execute('''
                CREATE TABLE IF NOT EXISTS portfolio_allocations (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    portfolio_id INTEGER NOT NULL,
                    etf_code TEXT NOT NULL,
                    target_weight REAL NOT NULL,
                    current_weight REAL DEFAULT 0,
                    current_value REAL DEFAULT 0,
                    shares INTEGER DEFAULT 0,
                    last_rebalanced TEXT,
                    created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (portfolio_id) REFERENCES portfolios(id),
                    FOREIGN KEY (etf_code) REFERENCES etf_info(code),
                    UNIQUE(portfolio_id, etf_code)
                )
            ''')
            
            # ì¸ë±ìŠ¤ ìƒì„±
            conn.execute('CREATE INDEX IF NOT EXISTS idx_etf_info_category ON etf_info(category)')
            conn.execute('CREATE INDEX IF NOT EXISTS idx_etf_info_active ON etf_info(is_active)')
            conn.execute('CREATE INDEX IF NOT EXISTS idx_etf_prices_code_date ON etf_prices(code, date)')
            conn.execute('CREATE INDEX IF NOT EXISTS idx_portfolio_allocations_portfolio ON portfolio_allocations(portfolio_id)')
            
            conn.commit()
            conn.close()
            
            logger.info("ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ìƒì„± ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def get_market_status(self) -> Dict:
        """ì‹œì¥ ìƒíƒœ ì •ë³´"""
        now = datetime.now()
        last_business_day = self.get_last_business_day()
        
        # ì‹œì¥ ì‹œê°„ ì²´í¬ (í•œêµ­ ì‹œì¥: 09:00-15:30)
        market_open = now.replace(hour=9, minute=0, second=0, microsecond=0)
        market_close = now.replace(hour=15, minute=30, second=0, microsecond=0)
        
        is_trading_hours = market_open <= now <= market_close and now.weekday() < 5
        
        return {
            'current_time': now.isoformat(),
            'last_business_day': last_business_day,
            'is_trading_hours': is_trading_hours,
            'market_open': market_open.time().isoformat(),
            'market_close': market_close.time().isoformat(),
            'is_weekend': now.weekday() >= 5,
            'pykrx_available': PYKRX_AVAILABLE,
            'cache_size': len(self.cache),
            'api_delay': self.api_delay
        }
    
    def clear_cache(self):
        """ìºì‹œ ì´ˆê¸°í™”"""
        cache_size = len(self.cache)
        self.cache.clear()
        logger.info(f"ìºì‹œ ì´ˆê¸°í™” ì™„ë£Œ: {cache_size}ê°œ í•­ëª© ì‚­ì œë¨")
    
    def get_health_check(self) -> Dict:
        """ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""
        try:
            # ê°„ë‹¨í•œ API í…ŒìŠ¤íŠ¸
            test_success = False
            if PYKRX_AVAILABLE:
                try:
                    test_tickers = stock.get_etf_ticker_list()[:1]
                    if test_tickers:
                        self._rate_limit()
                        test_data = stock.get_market_ohlcv_by_date(
                            self.get_last_business_day(), 
                            self.get_last_business_day(), 
                            test_tickers[0]
                        )
                        test_success = not test_data.empty
                except:
                    test_success = False
            
            return {
                'pykrx_available': PYKRX_AVAILABLE,
                'api_working': test_success,
                'cache_items': len(self.cache),
                'db_exists': os.path.exists(self.db_path) if hasattr(os, 'path') else False,
                'last_api_call': self.last_api_call,
                'status': 'healthy' if test_success else 'degraded'
            }
            
        except Exception as e:
            return {
                'pykrx_available': PYKRX_AVAILABLE,
                'api_working': False,
                'cache_items': len(self.cache),
                'error': str(e),
                'status': 'error'
            }
    
    def safe_get_etf_list_with_retry(self, max_retries: int = 3) -> List[Dict]:
        """ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ì•ˆì „í•œ ETF ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ"""
        
        for attempt in range(max_retries):
            try:
                logger.info(f"ETF ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ ì‹œë„ {attempt + 1}/{max_retries}")
                
                etf_list = self.get_all_etf_list()
                
                if etf_list and len(etf_list) > 0:
                    logger.info(f"ETF ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ ì„±ê³µ: {len(etf_list)}ê°œ")
                    return etf_list
                else:
                    logger.warning(f"ì‹œë„ {attempt + 1}: ETF ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŒ")
                    
            except Exception as e:
                logger.error(f"ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {str(e)}")
                
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 5  # 5, 10, 15ì´ˆ ëŒ€ê¸°
                    logger.info(f"{wait_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                    time.sleep(wait_time)
                    
                    # API ì§€ì—°ì‹œê°„ ì¦ê°€
                    self.api_delay = min(self.api_delay * 1.5, 2.0)
                    logger.info(f"API ì§€ì—°ì‹œê°„ ì¦ê°€: {self.api_delay:.1f}ì´ˆ")
        
        # ëª¨ë“  ì‹œë„ ì‹¤íŒ¨ì‹œ ê¸°ë³¸ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        logger.warning("ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ - ê¸°ë³¸ ETF ë¦¬ìŠ¤íŠ¸ ë°˜í™˜")
        return self._get_default_etf_list()


# ==========================================
# ì‹¤í–‰ ì˜ˆì œ ë° í…ŒìŠ¤íŠ¸ ì½”ë“œ
# ==========================================

if __name__ == "__main__":
    print("ğŸ“Š pykrx ê¸°ë°˜ ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ê¸° í…ŒìŠ¤íŠ¸ (ìˆ˜ì • ë²„ì „)")
    print("=" * 60)
    
    # ë¡œê¹… ë ˆë²¨ ì„¤ì •
    logging.basicConfig(level=logging.INFO)
    
    # ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
    collector = MarketDataCollector()
    
    # ì‹œì¥ ìƒíƒœ í™•ì¸
    print("\nğŸ“ˆ ì‹œì¥ ìƒíƒœ:")
    market_status = collector.get_market_status()
    print(f"í˜„ì¬ ì‹œê°„: {market_status['current_time'][:19]}")
    print(f"ìµœì¢… ì˜ì—…ì¼: {market_status['last_business_day']}")
    print(f"ê±°ë˜ ì‹œê°„: {'ì˜ˆ' if market_status['is_trading_hours'] else 'ì•„ë‹ˆì˜¤'}")
    print(f"ì£¼ë§: {'ì˜ˆ' if market_status['is_weekend'] else 'ì•„ë‹ˆì˜¤'}")
    print(f"pykrx ì‚¬ìš© ê°€ëŠ¥: {'ì˜ˆ' if market_status['pykrx_available'] else 'ì•„ë‹ˆì˜¤'}")
    
    # ETF ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ í…ŒìŠ¤íŠ¸
    print(f"\nğŸ“‹ ETF ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ í…ŒìŠ¤íŠ¸:")
    etf_list = collector.get_all_etf_list()
    print(f"ì´ ETF ê°œìˆ˜: {len(etf_list)}")
    
    if etf_list:
        print(f"\nìƒìœ„ 5ê°œ ETF:")
        for i, etf in enumerate(etf_list[:5]):
            print(f"{i+1}. {etf['name']} ({etf['code']}): {etf['market_price']:,.0f}ì›, ê±°ë˜ëŸ‰: {etf.get('volume', 0):,}ì£¼")
    
    # ê°œë³„ ETF ê°€ê²© ë°ì´í„° í…ŒìŠ¤íŠ¸
    if etf_list:
        test_ticker = etf_list[0]['code']
        print(f"\nğŸ“Š {test_ticker} ê°€ê²© ë°ì´í„° í…ŒìŠ¤íŠ¸:")
        
        price_data = collector.fetch_etf_price_data(test_ticker, "1m")
        if not price_data.empty:
            print(f"ë°ì´í„° ê¸°ê°„: {price_data['date'].min().date()} ~ {price_data['date'].max().date()}")
            print(f"ë°ì´í„° í¬ì¸íŠ¸: {len(price_data)}ê°œ")
            print(f"ì»¬ëŸ¼: {list(price_data.columns)}")
            print(f"ìµœì‹  ê°€ê²©: {price_data['close'].iloc[-1]:,.0f}ì›")
            
            # ì„±ê³¼ ì§€í‘œ ê³„ì‚°
            metrics = collector.calculate_performance_metrics(price_data)
            print(f"ì´ ìˆ˜ìµë¥ : {metrics.get('total_return', 0):.2f}%")
            print(f"ë³€ë™ì„±: {metrics.get('volatility', 0):.2f}%")
            print(f"ìƒ¤í”„ ë¹„ìœ¨: {metrics.get('sharpe_ratio', 0):.3f}")
        else:
            print("ê°€ê²© ë°ì´í„° ì—†ìŒ")
    
    # ë¬¸ì œ ì¢…ëª© í…ŒìŠ¤íŠ¸
    print(f"\nğŸ”§ ë¬¸ì œ ì¢…ëª©ë“¤ í…ŒìŠ¤íŠ¸:")
    problem_tickers = ['427120', '495710']
    
    for problem_ticker in problem_tickers:
        try:
            print(f"\n--- {problem_ticker} í…ŒìŠ¤íŠ¸ ---")
            problem_etf_info = collector._get_etf_basic_info(problem_ticker, collector.get_last_business_day())
            if problem_etf_info:
                print(f"{problem_ticker} ì •ë³´: {problem_etf_info['name']} - {problem_etf_info['market_price']:,}ì›")
            else:
                print(f"{problem_ticker} ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ (ì •ìƒ ì²˜ë¦¬ë¨)")
            
            problem_price_data = collector.fetch_etf_price_data(problem_ticker, "1w")
            print(f"{problem_ticker} ê°€ê²© ë°ì´í„°: {len(problem_price_data)}ê±´")
            
            if not problem_price_data.empty:
                print(f"  ìµœì‹  ê°€ê²©: {problem_price_data['close'].iloc[-1]:,.0f}ì›")
                print(f"  ë°ì´í„° ê¸°ê°„: {problem_price_data['date'].min().date()} ~ {problem_price_data['date'].max().date()}")
            
        except Exception as e:
            print(f"{problem_ticker} í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {str(e)[:100]}...")
    
    # ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
    print(f"\nğŸ¥ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸:")
    health = collector.get_health_check()
    print(f"ìƒíƒœ: {health['status']}")
    print(f"API ì‘ë™: {'ì˜ˆ' if health['api_working'] else 'ì•„ë‹ˆì˜¤'}")
    print(f"ìºì‹œ í•­ëª©: {health['cache_items']}ê°œ")
    
    # ì•ˆì „í•œ ì¬ì‹œë„ í…ŒìŠ¤íŠ¸
    print(f"\nğŸ”„ ì¬ì‹œë„ ë¡œì§ í…ŒìŠ¤íŠ¸:")
    safe_etf_list = collector.safe_get_etf_list_with_retry(max_retries=2)
    print(f"ì¬ì‹œë„ ê²°ê³¼: {len(safe_etf_list)}ê°œ ETF")
    
    print(f"\nâœ… ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ê¸° í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")